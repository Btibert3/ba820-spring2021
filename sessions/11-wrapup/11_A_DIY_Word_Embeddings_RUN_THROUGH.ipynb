{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11 - A - DIY Word Embeddings - RUN THROUGH",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-1HSJ5CjFck"
      },
      "source": [
        "# Word Embeddings via Word2Vec\n",
        "\n",
        "Instead of using pre-trained models, if you really needed to, and had a large corpus, you could train your own embeddings in attempt to provide domain context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67FBU6AliXOk"
      },
      "source": [
        "# General Process\n",
        "\n",
        "- Define our corpus == universe assumption (we have captured the vocabulary well enough in our corpus)\n",
        "- Spacy to tokenize the text\n",
        "- List of lists -> gensim:word2vec (a each list has the tokens)\n",
        "- Gensim Word2Vec\n",
        "- Tell spacy about our vectors\n",
        "\n",
        "> We will use a smaller corpus to highlight tradeoffs of training our own\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzRk_NDRmVSK"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import spacy\n",
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdxS0LGXqOdD"
      },
      "source": [
        "# initalize spacy -- we are going to bring our own model\n",
        "#                    so small is fine (and explicit)\n",
        "\n",
        "MODEL = \"en_core_web_sm\"\n",
        "spacy.cli.download(MODEL)\n",
        "\n",
        "### ok, we have that model, lets build our own\n",
        "nlp = spacy.load(MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcRp4F8psLDd"
      },
      "source": [
        "# get the data == universe\n",
        "\n",
        "SQL = \"SELECT * from `datasets.airline-intents`\"\n",
        "\n",
        "intents = pd.read_gbq(SQL, \"questrom\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BYf_yxatYAL"
      },
      "source": [
        "# get a sample to see what we have\n",
        "intents.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqUcefMiunuE"
      },
      "source": [
        "intents.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K58HR_aNoh3c"
      },
      "source": [
        "## Step 1: spacy tokenize text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOuVUTviqOmy"
      },
      "source": [
        "# tokenize the corpus\n",
        "\n",
        "def tokenize(text):\n",
        "  doc = nlp(text)\n",
        "  return [token.text for token in doc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CguFwDfpv4t"
      },
      "source": [
        "# apply it to the text column\n",
        "intents['tokens'] = intents.text.apply(tokenize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D85F-BC2nJrq"
      },
      "source": [
        "# another sample\n",
        "intents.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0duYFQou-BO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPp98tvt1X_e"
      },
      "source": [
        "## Step 2 : Gensim Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5_iChR63R7y"
      },
      "source": [
        "# gensim\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA2Q_K5MoCcm"
      },
      "source": [
        "# extract tokens as a list of lists\n",
        "\n",
        "docs = intents.tokens.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klz32ildvZvg"
      },
      "source": [
        "docs[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWUmJNHm1YDs"
      },
      "source": [
        "# fit the model \n",
        "# 50 feature vectors, a context window of 3, and skipgram model\n",
        "# https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec\n",
        "\n",
        "model = Word2Vec(docs, size=50, window=3, sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjnhOzWUp4c2"
      },
      "source": [
        "# what do we have\n",
        "type(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIVSS5jvp70s"
      },
      "source": [
        "# we have some basics\n",
        "\n",
        "model.corpus_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR2Skyjuv1he"
      },
      "source": [
        "intents.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRpcv_hkp19_"
      },
      "source": [
        "# what is the size of our vocab?\n",
        "\n",
        "len(model.wv.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lnpaq5V1YGV"
      },
      "source": [
        "# get vocab vectors\n",
        "\n",
        "model.wv.get_vector('the')\n",
        "model.wv.get_vector('flight')\n",
        "model.wv.get_vector('boston')\n",
        "model.wv.get_vector('help')\n",
        "\n",
        "\n",
        "## it fails hard on a lookup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU5jkEDa1YKt"
      },
      "source": [
        "# we can also compare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3zLEIIrJpqD"
      },
      "source": [
        "# we can look at the most similar vectors for a token\n",
        "\n",
        "model.wv.most_similar(\"boston\")\n",
        "model.wv.most_similar(\"flight\")\n",
        "# model.wv.most_similar(\"the\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wExGK4NqskWj"
      },
      "source": [
        "# Step 3: Save and load into spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS4Glyyxps_s"
      },
      "source": [
        "# ok, lets save this out to a text file\n",
        "model.wv.save_word2vec_format(\"word2vec.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzj4HgeMGmtZ"
      },
      "source": [
        "# we are going to compres the file\n",
        "\n",
        "! gzip word2vec.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHRA9L1AxdJW"
      },
      "source": [
        "! ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4EBZun6IKlp"
      },
      "source": [
        "# inform spacy of a new model, \n",
        "# https://spacy.io/api/cli#init-vectors\n",
        "# we are on spacy 2\n",
        "\n",
        "! python -m spacy init-model en brock-model --vectors-loc word2vec.txt.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmPSl1IcIMkp"
      },
      "source": [
        "# rename this to whatever you have above\n",
        "nlp = spacy.load(\"brock-model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L_fXeECIag_"
      },
      "source": [
        "# lets check the vectors are being used\n",
        "# check boston\n",
        "\n",
        "nlp(\"boston\").vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLhwhKwxItLk"
      },
      "source": [
        "# compare that we are using the same\n",
        "# model.wv.get_vector(\"boston\")\n",
        "\n",
        "# compare spacy and gensim are the same\n",
        "nlp(\"boston\").vector == model.wv.get_vector(\"boston\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIHGWNwUIt98"
      },
      "source": [
        "# all the other bits still apply\n",
        "test = nlp(\"This is the example please btibert@bu.edu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUaLSIioI2SU"
      },
      "source": [
        "# lets confirm\n",
        "\n",
        "for token in test:\n",
        "  print(token.text, token.lemma_, token.like_email, token.is_oov)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkbntlIdI63b"
      },
      "source": [
        "## what does above tell us about building our own?\n",
        "## what might we need to \"improve\" our model/vectors?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMC_2S6sgO5G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "livBlURcdTUV"
      },
      "source": [
        "## Where to go from here\n",
        "\n",
        "- fastText vectors [use txt not bin]: https://github.com/facebookresearch/fastText/blob/master/docs/crawl-vectors.md#models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN6gfls7ddBk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}