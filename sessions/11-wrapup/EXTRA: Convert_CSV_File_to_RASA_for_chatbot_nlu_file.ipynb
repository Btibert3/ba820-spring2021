{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convert CSV File to RASA for chatbot nlu file",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv-5PXppztSx"
      },
      "source": [
        "# imports\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKteFZ2d0FuM"
      },
      "source": [
        "# get the intents dataset\n",
        "SQL = \"SELECT * from `datasets.airline-intents`\"\n",
        "PROJ = \"questrom\"\n",
        "\n",
        "\n",
        "intents = pd.read_gbq(SQL, PROJ)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaQ9j_EF16KE"
      },
      "source": [
        "# reminder of what we have\n",
        "intents.intent.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGlq426t63BT"
      },
      "source": [
        "### sourced from here: https://github.com/lohithpro/csvtorasa/blob/master/csvtorasa.py\n",
        "## I tweaked below for colab\n",
        "\n",
        "def create_rasa_files(path, create_files_path):\n",
        "    \"\"\"\n",
        "    Converts an CSV file created with the specified format to RASA accepted nlu.md format\n",
        "    :param path: path where the CSV file is present\n",
        "    :param create_files_path: path where the nlu.md file needs to be created\n",
        "    :return: return nothing. A file is created in the path specified via create_files_path\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(r\"{}\".format(path))\n",
        "    file = open(r'{}/nlu.md'.format(create_files_path), \"w\")\n",
        "    intents = list(df.columns)\n",
        "    for item in intents:\n",
        "        file.write(\"## intent: {intent_name}\\n\".format(intent_name=item))\n",
        "        for sent in df[item]:\n",
        "            file.write(\"- {}\\n\".format(sent))\n",
        "    file.close()\n",
        "    file = open(r'{}/domain.yml'.format(create_files_path), \"w\")\n",
        "    file.write(\"intents:\\n\")\n",
        "    for intent_name in intents:\n",
        "        file.write(\"  - {}\\n\".format(intent_name))\n",
        "    file.write(\"actions:\\n\")\n",
        "    for intent_name in intents:\n",
        "        file.write(\"  - utter_{}\\n\".format(intent_name))\n",
        "    file.close()\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LONpJ-F1fG3"
      },
      "source": [
        "# I would have expected to actually parse a dataframe\n",
        "# but its easy enough I suppose\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUJAmbbo1fEm"
      },
      "source": [
        "############################## only keep intents with a # of records\n",
        "# 20 examples per intent, more, in theory, better\n",
        "\n",
        "# how many intents to keep based on frequency\n",
        "THRESH = 20\n",
        "F = intents.intent.value_counts() > THRESH\n",
        "i2k = intents.intent.value_counts()[F]\n",
        "\n",
        "top_intents = i2k.index.to_list()\n",
        "\n",
        "## filter the list of intents to those with the threshold volume\n",
        "intents2 = intents.loc[intents.intent.isin(top_intents), :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcMlcmq71fAL"
      },
      "source": [
        "# for each of the top intents, build a dictionary of intent:example pairs\n",
        "intent_d = {}\n",
        "for intent in top_intents:\n",
        "  tmp = intents2.loc[intents2.intent==intent, :]\n",
        "  examples = tmp.text.tolist()\n",
        "  intent_d[str(intent)] = examples\n",
        "\n",
        "\n",
        "# intent_d.keys()\n",
        "\n",
        "\n",
        "# make it a dataframe\n",
        "intent_nlu = pd.DataFrame.from_dict(intent_d, orient='index').transpose()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgFGOHdP1e9j"
      },
      "source": [
        "# type(intent_nlu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PVR5UEZ1e4d"
      },
      "source": [
        "# shape\n",
        "intent_nlu.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKY31YHz8IgT"
      },
      "source": [
        "# first few rows\n",
        "intent_nlu.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poH5RycE9xZH"
      },
      "source": [
        "# not all rows are valid per intent\n",
        "# missing is fine\n",
        "\n",
        "# write the file\n",
        "intent_nlu.to_csv(\"intents.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0mH9VPL1H98"
      },
      "source": [
        "# use the nlu function\n",
        "create_rasa_files(\"intents.csv\", \"/content/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjoOjQk_C84i"
      },
      "source": [
        "# what do we have now\n",
        "! ls -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbE2uaskC897"
      },
      "source": [
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTxy4AlqC9Ar"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}